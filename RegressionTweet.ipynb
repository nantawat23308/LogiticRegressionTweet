{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085115d4-2246-4411-b324-c32ac32322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedf7264-970d-4f0b-a3ea-638272c389e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\nsrisuwo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nsrisuwo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2450a3-fb3a-41f3-90cd-c64ec4ebcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52914910-a9d1-453d-83ac-7b9fd53d1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb6a301-6152-4b63-af35-7308984a8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abb45d4-d063-496f-b19e-fedcb6e6740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307908b5-6462-474d-9da6-6b92ae658032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11427\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab7fe6c-8cac-48b2-873d-32ba03313d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc47de-4ef8-4a3c-b024-7da957875198",
   "metadata": {},
   "source": [
    "<a name='1'></a>\r\n",
    "## 1 - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dadfbd62-ca42-440d-b88c-480e3620175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    h = 1 / (1 + (np.exp(-z)))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236eb47e-6b9c-42a3-ad23-da62b56c62c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b7ce4-c760-4d50-9f71-94ed939abaa6",
   "metadata": {},
   "source": [
    "The cost function used for logistic regression is the average of the log loss across all training\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019648c-de5e-4368-ba3b-c34bb0d800f7",
   "metadata": {},
   "source": [
    "The loss function for a single training example is\r\n",
    "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d73e64-1e1d-4cc2-a477-af16d4d0204c",
   "metadata": {},
   "source": [
    "#### Update the weights\r\n",
    "\r\n",
    "To update your weight vector $\\theta$, you will apply gradient descent to iteratively improve your model's predictions.  \r\n",
    "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\r\n",
    "\r\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j \\tag{5}$$\r\n",
    "* 'i' is the index across all 'm' training examples.\r\n",
    "* 'j' is the index of the weight $\\theta_j$, so $x^{(i)}_j$ is the feature associated with weight $\\theta_j$\r\n",
    "\r\n",
    "* To update the weight $\\theta_j$, we adjust it by subtracting a fraction of the gradient determined by $\\alpha$:\r\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\r\n",
    "* The learning rate $\\alpha$ is a value that we choose to control how big a single update will be.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f149802a-3af8-484d-8bfd-f590e8b3d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        z = x.dot(theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -(1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n",
    "\n",
    "        theta = theta - ((alpha / m) * (x.T.dot(h-y)))\n",
    "        \n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110b2b2-86b7-4139-b23c-0d01cee0c3c9",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Extracting the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc147a4a-7a02-4ed6-b948-0b7bf3ca4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string containing one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements for [bias, positive, negative] counts\n",
    "    x = np.zeros(3) \n",
    "    x[0] = 1 \n",
    "    \n",
    "    for word in word_l:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        # increment the word count for the positive label 1\n",
    "        if (word, 1) in freqs:\n",
    "            pos = freqs[(word, 1)]\n",
    "            x[1] += pos\n",
    "        # increment the word count for the negative label 0\n",
    "        if (word, 0) in freqs:\n",
    "            neg = freqs[(word, 0)]\n",
    "            x[2] += neg\n",
    "    x = x[None, :]  # adding batch dimension for further processing\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b4ff41-1037-4f61-adf7-306b52362d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 3.133e+03 6.100e+01]]\n"
     ]
    }
   ],
   "source": [
    "tmp1 = extract_features(train_x[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad6cc61-d5ac-4c82-9a94-412c9106bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f519af-9c72-45e5-827f-a6cd008934fb",
   "metadata": {},
   "source": [
    "<a name='3'></a>\r\n",
    "## 3 - Training Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68af1e29-7443-43ce-a704-b944d62921b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.22521264.\n",
      "The resulting vector of weights is [6e-08, 0.0005382, -0.0005583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsrisuwo\\AppData\\Local\\Temp\\ipykernel_8376\\931480022.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f6030-ad26-4a81-bf92-efb80e33a886",
   "metadata": {},
   "source": [
    "<a name='4'></a>\r\n",
    "## 4 -  Testr Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f2fe0be-1769-48d9-a185-85adbbc9f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    x = extract_features(tweet, freqs)\n",
    "    y_pred = sigmoid(x.dot(theta))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f4459a1-6ef9-4f4c-b1cc-f3b08781c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.519275\n",
      "I am bad -> 0.494347\n",
      "this movie should have been great. -> 0.515980\n",
      "great -> 0.516065\n",
      "great great -> 0.532097\n",
      "great great great -> 0.548063\n",
      "great great great great -> 0.563930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsrisuwo\\AppData\\Local\\Temp\\ipykernel_8376\\3892372758.py:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n"
     ]
    }
   ],
   "source": [
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f801009c-6c75-4941-84f8-91aecda53e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83110764]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tweet = 'I am learning :)'\n",
    "predict_tweet(my_tweet, freqs, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e606346-3df6-4ec0-aa86-ebea41ea8dd8",
   "metadata": {},
   "source": [
    "Check the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f294d589-ca67-4b29-a20a-87b31b65481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0.0)\n",
    "    count = 0 \n",
    "    for i in range(len(y_hat)):\n",
    "        if y_hat[i] == test_y[i][0]:\n",
    "            count += 1\n",
    "    \n",
    "    accuracy = count/ (test_y.shape[0])\n",
    "    accuracy = np.float64(accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca7bf702-8551-4f0a-9a97-3a1c56e8bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9950\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3bb5f10-1594-478e-8e40-918e2d8ab1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0.48942981\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418981\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418981\tb\"i'm play brain dot braindot\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsrisuwo\\AppData\\Local\\Temp\\ipykernel_8376\\3590713043.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48418981\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: off to the park to get some sunlight : )\n",
      "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
      "1\t0.49636406\tb'park get sunlight'\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.48250522\tb'uff itna miss karhi thi ap :p'\n",
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.50988296\tb'u prob fun david'\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t0.50040366\tb'pat jay'\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "0\t0.50000002\tb'belov grandmoth'\n",
      "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t0.50648699\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
     ]
    }
   ],
   "source": [
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062390c-9347-455b-be47-10918e906f39",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63efbfaa-9ae2-4686-8401-c46d4b498446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
      "[[0.48125421]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366f97a-74c6-4261-a328-f129ea5316d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
